{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hồi quy tuyến tính\n",
    "*Hoàn thành toàn bộ phần bài tập trong notebook này, bao gồm toàn bộ kết quả đầu ra và code hỗ trợ.*\n",
    "\n",
    "***\"Không có một sự kiện nào trên đời là ngẫu nhiên, những thứ đang cho là ngẫu nhiên chỉ là những sự kiện ta chưa tìm ra được mô hình để biểu diễn quy luật của chúng\".***\n",
    "\n",
    "Xây dựng mô hình **Hồi quy tuyến tính** bao gồm hai phần:\n",
    "- Trong quá trình huấn luyện, bộ phân lớp lấy dữ liệu huấn luyện và và học các tham số mô hình.\n",
    "- Trong quá trình kiếm tra, mô hình phân lớp từng đối tượng bằng cách nhân giá trị của mẫu với các tham số mô hình để tìm ra giá trị của nhãn.\n",
    "- Giá trị của tham số được kiểm định chéo.\n",
    "Trong bài tập này, bạn sẽ cài đặt những bước trên và hiểu được qui trình Xây dựng một mô hình đơn giản với Học tham số, kiểm định chéo, và hiểu được cách viết code hiệu quả với vectorize.\n",
    "\n",
    "Bài toán dự đoán giá nhà Boston được sử dụng trong bài tập này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import một số thư viện cần thiết.\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sử dụng một mẹo nhỏ để vẽ hình trên cùng một dòng thay vì mở cửa sổ mới\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # đặt kích thước mặc định cho hình\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Một mẹo nhỏ để notebook tự load lại các module bên ngoài;\n",
    "# xem thêm tại http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (404, 13)\n",
      "Training labels shape:  (404,)\n",
      "Test data shape:  (102, 13)\n",
      "Test labels shape:  (102,)\n"
     ]
    }
   ],
   "source": [
    "# Tải dữ liệu Giá nhà Boston từ Scikit-learn.\n",
    "boston = datasets.load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, \\\n",
    "                                                    boston.target, test_size=0.2)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dữ liệu\n",
    "Hồi qui tuyến tính đơn giản là một cách tiếp cận để dự đoán phản ứng (giá trị đầu ra) khi dữ liệu có một đặc trưng duy nhất. Khi giả sử hai biến $x$ và $y$ liên hệ tuyến  tính thì mục tiêu của mô hình là cố tìm ra đường tuyến tính tốt nhất để dự đoán phản ứng ($y$). \n",
    "\n",
    "Đường đó được gọi là đường hồi quy.\n",
    "\n",
    "Công thức cho đường hồi quy được biểu diễn như sau:\n",
    "$$ \\hat{Y} = h(X) = XW$$\n",
    "Trong đó: \n",
    "\n",
    "- $X$ là ma trận có kích thước $N \\times D$ với $X_{ij}$ là giá trị của đặc trưng thứ $j$ của mẫu $i$.\n",
    "- $W$ là ma trận tham số có kích thước $D \\times 1$\n",
    "- $Y$ là giá trị phản ứng của $N$ mẫu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAHjCAYAAABrZcgFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x237b7b9c668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Biểu diễn một số ví dụ trong tập huấn luyện sử dụng một đặc trưng duy nhất.\n",
    "# LSTAT - % lower status of the population\n",
    "plt.scatter(X_train[:,12], y_train)\n",
    "plt.xlabel(\"Crime rate\")\n",
    "plt.ylabel(\"House's price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huấn luyện mô hình\n",
    "Tất cả code cho phần bài tập này được lưu trong tệp **models/linear_regression.py** và **models/linear_loss.py**.\n",
    "### Cập nhật tham số\n",
    "Quá trình huấn luyện mô hình thực chất là từ dữ liệu để học ra tham số mô hình phù hợp nhất với mô hình sinh dữ liệu. Trong mô hình hồi quy tuyến tính, ta cần học tham số $W$.\n",
    "\n",
    "Khi khởi tạo mô hình, ta giả sử tham số được khởi tạo ngẫu nhiên. Sử dụng tham số $W$ đó, ta ước lượng được giá trị $Y$:\n",
    "$$ \\hat{y} = h(X) = WX $$\n",
    "\n",
    "Tổng sai số, độ lệch của giá trị dự đoán so với giá trị thực tế gọi là hàm giá trị (Cost function):\n",
    "$$ J(w) = \\frac{1}{2N}\\sum_{i=1}^{N} (\\hat{y}_i - y_i)^2 = \\frac{1}{2N}\\sum_{i=1}^{N} (\\sum_{j=1}^{D}w_jx_{ij} - y_i)^2$$\n",
    "\n",
    "\n",
    "Chúng ta sử thuật toán **xuống đồi (Gradient descent)** để tối ưu tham số $W$. (Xem khóa [Machine Learning](https://www.coursera.org/learn/machine-learning/))\n",
    "\n",
    "Đột tụt dốc của tham số $W$ được cập nhật theo công thức:\n",
    "$$ dw_i = \\frac{\\partial}{\\partial w_i}J(w) = \\frac{1}{N}\\sum_{j=1}^{N}x_{ji}(\\sum_{z=1}^{D}w_zx_{jz}-y_j) $$\n",
    "\n",
    "Đầu tiên, mở file ```models/linear_loss.py``` và cài đặt hàm ```linear_loss_naive```, sử dụng vòng lặp để tính hàm giá trị (Cost function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 316.083138\n"
     ]
    }
   ],
   "source": [
    "from models.linear_loss import linear_loss_naive\n",
    "import time\n",
    "\n",
    "# sinh ngẫu nhiên các trọng số (W) với các giá trị nhỏ\n",
    "W = np.random.randn(13, ) * 0.0001 \n",
    "\n",
    "loss, grad = linear_loss_naive(W, X_test, y_test, 0.00001)\n",
    "print('loss: %f' % (loss, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lúc này, các giá trị gradient được trả về đều bằng 0. Đạo hàm và tính gradient theo công thức được cho ở trên trong cùng hàm ```linear_loss_naive```. Bạn sẽ thấy một số thứ hữu ích trong phần cài đặt trước đó.\n",
    "\n",
    "Để đảm bảo là bạn đã cài đặt đúng, chúng ta sẽ sử dụng hàm ```grad_check_sparse``` (đã được cài đặt sẵn) để kiểm tra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -8481.931778 analytic: -8481.931778, relative error: 1.463653e-13\n",
      "numerical: -150.197248 analytic: -150.197248, relative error: 1.265064e-11\n",
      "numerical: -51.258319 analytic: -51.258319, relative error: 5.010489e-11\n",
      "numerical: -178.534885 analytic: -178.534885, relative error: 1.262585e-11\n",
      "numerical: -8481.931778 analytic: -8481.931778, relative error: 1.463653e-13\n",
      "numerical: -100.959374 analytic: -100.959374, relative error: 2.162109e-11\n",
      "numerical: -199.733789 analytic: -199.733789, relative error: 1.906309e-11\n",
      "numerical: -199.733789 analytic: -199.733789, relative error: 1.906309e-11\n",
      "numerical: -224.177480 analytic: -224.177480, relative error: 1.286839e-11\n",
      "numerical: -199.733789 analytic: -199.733789, relative error: 1.906309e-11\n",
      "numerical: -492.804357 analytic: -492.804357, relative error: 6.313451e-12\n",
      "numerical: -100.950863 analytic: -100.950863, relative error: 2.052173e-11\n",
      "numerical: -224.159606 analytic: -224.159606, relative error: 1.464990e-11\n",
      "numerical: -8514.295401 analytic: -8514.295401, relative error: 1.603364e-13\n",
      "numerical: -1.057232 analytic: -1.057232, relative error: 7.736673e-12\n",
      "numerical: -178.528611 analytic: -178.528611, relative error: 1.317760e-11\n",
      "numerical: -1368.041530 analytic: -1368.041530, relative error: 2.763636e-12\n",
      "numerical: -150.206467 analytic: -150.206467, relative error: 1.353530e-11\n",
      "numerical: -199.733824 analytic: -199.733824, relative error: 2.029439e-11\n",
      "numerical: -8481.930234 analytic: -8481.930234, relative error: 1.317824e-13\n"
     ]
    }
   ],
   "source": [
    "# Bởi vì bạn đã cài đặt hàm gradient, tính toán gradient với code dưới đây và\n",
    "# kiểm tra với hàm grad_check_sparse(...) đã cho.\n",
    "\n",
    "# Tính toán loss và grad với W.\n",
    "loss, grad = linear_loss_naive(W, X_test, y_test, 0.0)\n",
    "\n",
    "# Tính toán gradient theo một số chiều ngẫu nhiên và so sánh chúng với kết quả\n",
    "# của bạn. Giá trị phải gần như chính xác theo tất cả các chiều.\n",
    "from models.gradient_check import grad_check_sparse\n",
    "f = lambda w: linear_loss_naive(w, X_test, y_test, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad)\n",
    "\n",
    "# thực hiện kiểm tra khi có sử dụng regularization\n",
    "# đừng quên cài đặt gradient với regularization nhé.\n",
    "loss, grad = linear_loss_naive(W, X_test, y_test, 1e2)\n",
    "f = lambda w: linear_loss_naive(w, X_test, y_test, 1e2)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad)\n",
    "\n",
    "# Kết quả relative error trong khoảng 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive loss: 3.160831e+02 computed in 0.000000s\n",
      "Vectorized loss: 3.160831e+02 computed in 0.000000s\n",
      "difference: -0.000000\n"
     ]
    }
   ],
   "source": [
    "# Kế tiếp, cài đặt linear_loss_vectorized; hiện tại chỉ tính toán hàm giá trị;\n",
    "# gradient sẽ cài đặt sau.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = linear_loss_naive(W, X_test, y_test, 0.00001)\n",
    "toc = time.time()\n",
    "print('Naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "# Vectorized\n",
    "from models.linear_loss import linear_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, _ = linear_loss_vectorized(W, X_test, y_test, 0.00001)\n",
    "toc = time.time()\n",
    "print('Vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# Hàm giá trị khi vectorized nên có cùng giá trị với giá trị được tính bằng hàm\n",
    "# linear_loss_naive() nhưng tính toán nhanh hơn\n",
    "print('difference: %f' % (loss_naive - loss_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive loss and gradient: computed in 0.000000s\n",
      "Vectorized loss and gradient: computed in 0.035192s\n",
      "difference: 2.581423003824335e-12\n"
     ]
    }
   ],
   "source": [
    "# Hoàn thiện phần cài đặt của linear_loss_vectorized, và tính toán gradient theo\n",
    "# cách vectorized.\n",
    "\n",
    "# Hai hàm tính loss và gradient nên cho kết quả giống nhau nhưng bản vectorized \n",
    "# tính toán nhanh hơn.\n",
    "tic = time.time()\n",
    "_, grad_naive = linear_loss_naive(W, X_test, y_test, 0.00001)\n",
    "toc = time.time()\n",
    "print('Naive loss and gradient: computed in %fs' % (toc - tic))\n",
    "\n",
    "tic = time.time()\n",
    "_, grad_vectorized = linear_loss_vectorized(W, X_test, y_test, 0.00001)\n",
    "toc = time.time()\n",
    "print('Vectorized loss and gradient: computed in %fs' % (toc - tic))\n",
    "\n",
    "# So sánh gradient\n",
    "difference = np.linalg.norm(grad_naive - grad_vectorized)\n",
    "print('difference: {}'.format(difference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Huấn luyện với hàm cập nhật\n",
    "Sử dụng các hàm ```loss``` đã cài đặt ở trên để cài đặt hàm ```train``` trong tệp **linear_regression.py**.\n",
    "\n",
    "Tham số W được cập nhật từng thành phần theo công thức:\n",
    "$$ w_i =  w_i -\\alpha\\frac{\\partial}{\\partial w_i}J(w)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (13,1) doesn't match the broadcast shape (13,404)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-57305d4b5fd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m loss_hist = clf.train(X_train, y_train, learning_rate=1e-7, reg=5e4,\n\u001b[1;32m----> 7\u001b[1;33m                       num_iters=1500, verbose=True)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'That took %fs'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtoc\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\UNIVERSITY-UET\\TERM-6\\Machine-learning\\Machine-Learning\\week 4\\models\\linear_regression.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, learning_rate, reg, num_iters, verbose)\u001b[0m\n\u001b[0;32m     41\u001b[0m       \u001b[1;31m# Update the weights using the gradient and the learning rate.          #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m       \u001b[1;31m#########################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m       \u001b[1;31m#########################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m       \u001b[1;31m#                       END OF YOUR CODE                                #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (13,1) doesn't match the broadcast shape (13,404)"
     ]
    }
   ],
   "source": [
    "# Ở trong tệp linear_regression.py, cài đặt hàm LinearRegression.train() và chạy\n",
    "# hàm đó với code sau\n",
    "from models.linear_regression import LinearRegression\n",
    "clf = LinearRegression()\n",
    "tic = time.time()\n",
    "loss_hist = clf.train(X_train, y_train, learning_rate=1e-7, reg=5e4,\n",
    "                      num_iters=1500, verbose=True)\n",
    "toc = time.time()\n",
    "print('That took %fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-7bd2545198c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Một chiến thuật debug hiệu quả được sử dụng đó là vẽ ra lịch sử mất mát (loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# history) như là một hàm với số lần lặp.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_hist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iteration number'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss value'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_hist' is not defined"
     ]
    }
   ],
   "source": [
    "# Một chiến thuật debug hiệu quả được sử dụng đó là vẽ ra lịch sử mất mát (loss \n",
    "# history) như là một hàm với số lần lặp.\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cài đặt hàm LinearRegression.predict đánh giá hiệu năng mô hình trên cả tập\n",
    "# huấn luyện và tệp kiểm tra.\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print('validation accuracy: %f' % (np.mean(y_test == y_test_pred), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sử dụng tập kiểm tra để điều chỉnh các siêu tham số (độ lớn của reg và tỉ\n",
    "# lệ học. Bạn nên thực nghiệm với nhiều khoảng giá trị của 2 siêu tham số này\n",
    "# Nếu bạn đủ cẩn thận, bạn có thể đạt độ chính xác ... trên tập kiểm tra.\n",
    "learning_rates = [1e-7, 5e-5]\n",
    "regularization_strengths = [5e4, 1e5]\n",
    "\n",
    "# kết quả là một từ điển ánh xạ từ tuple có dạng (reg, lr) sang tuple có dạng\n",
    "# (train_acc, test_acc). Độ chính xác chỉ đơn giản là tỉ lệ mẫu dự đoán chính\n",
    "# xác trên toàn tập dữ liệu.\n",
    "results = {}\n",
    "best_test = -1   # Hiệu năng tốt nhất mà chúng ta sẽ đạt được.\n",
    "best_linear = None # Mô hình LinearRegression có hiệu năng tốt nhất.\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Viết code chọn các siêu tham số tốt nhất bằng cách điều chỉnh trên tập kiểm  #\n",
    "# tra. Với mỗi tổ hợp siêu tham số, huấn luyện một mô hình LinearRegression    #\n",
    "# trên tập huấn luyện, tính toán độ chính xác trên tập huấn luyện và tập kiểm  #\n",
    "# tra, và lưu những con số này vào từ điển kết quả. Thêm vào đó, lưu hiệu năng #\n",
    "# tốt nhất trên tập kiểm tra vào best_val và mô hình LinearRegression tương    #\n",
    "# ứng vào best_svm.                                                            #  \n",
    "#                                                                              #\n",
    "# Gợi ý: Bạn nên sử dụng số vòng lặp (num_iters) nhỏ khi xây dựng code kiểm    #\n",
    "# tra để mô hình không mất quá nhiều thời gian để huấn luyện. Khi đã chắc chắn,#\n",
    "# bạn nên trả về kết quả với số vòng lặp lớn                                   #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                              KẾT THÚC                                        #\n",
    "################################################################################\n",
    "    \n",
    "# In kết quả\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, test_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, test_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize kết quả kiểm thử chéo\n",
    "import math\n",
    "x_scatter = [math.log10(x[0]) for x in results]\n",
    "y_scatter = [math.log10(x[1]) for x in results]\n",
    "\n",
    "# plot training accuracy\n",
    "marker_size = 100\n",
    "colors = [results[x][0] for x in results]\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors)\n",
    "plt.colorbar()\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('Boston training accuracy')\n",
    "\n",
    "# vẽ hiệu năng trên tập kiểm tra\n",
    "colors = [results[x][1] for x in results] # kích thước mặc định của marker là 20\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors)\n",
    "plt.colorbar()\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('Boston test accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
